{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MaskRCNN_Expln.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMtAKLIwC7q2O5iqu9DbKXi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tandem-team/Machine-Learning-Collection/blob/master/MaskRCNN_Expln.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DXItCGVYhLmw"
      },
      "source": [
        "##Mask RCNN Architecture Explanation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xrmrZKPthQzI"
      },
      "source": [
        "###1. Object detection , Semantic Segmentation and Instance segmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8wPuBrJkzJYu"
      },
      "source": [
        "\n",
        "Architectures like YOLO and SSD are efficient at the task of `object localization`, which is detecting objects in the image and drawing a bounding box around them. But the other major task in computer vision is `semantic segmentation` which is creating a pixel level boundary instead of a generic bounding box around the object. The pixel level classification allows for a much clearer distinction between different objects in the image.\n",
        "\\\n",
        "A specific case of semantic segmentation is `Instance segmentation` where in the pixels in the image, in addition to the different classes, are also classified based on the number of objects in each class.\n",
        "\\\n",
        "In this session, we'll discuss `Instance segmentaion`. Specifically, we will discuss Mask RCNN architecture which is uniquely designed for this task.\n",
        "\\\n",
        "\\\n",
        "<img src=\"https://files.ai-pool.com/d/DV8TLgkWsAEGsEs.jpg\" alt=\"MarineGEO circle logo\" style=\"height: 100px; width:100px;\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vz3JF1p2zJHX"
      },
      "source": [
        "##1.1 Mask RCNN architecture\n",
        "In 2017 Kaiming He et al. proposed Mask R-CNN. It was developed on top of Faster RCNN which is a Region-based Convolution Neural Net that performs Object Detection and returns bounding boxes and the corresponding class labels. To this architecture(i.e., Faster RCNN) a layer is added for predicting the segmentation values.\n",
        "\n",
        "###Architecture Explanation\n",
        "Mask RCNN, as the author explains, is a natural extension of the Faster RCNN detector.\n",
        "\n",
        "\n",
        "So similar to Faster RCNN, Mask RCNN has a backbone network and 2 stages there after.\n",
        "\\\n",
        "Backbone network : A pretrained CNN network usually Resnet50 or Resnet101. This is used as a feature extractor. The ouput feature map of this stage is fed to both the Stage1 and 2.\n",
        "\\\n",
        "Note: While Resnet works fine in this network, the authors of Mask RCNN have proposed an improved Feature Pyramid Network backbone for the architecture. For simplicity, this will be discussed later.\n",
        "\\\n",
        "Stage 1 : A lightweight neural network that takes the feature map and outputs a set of rectangular regions in the feature map which have the potential for an object of one of the desired classes. In the output, each rectangular region is associated with an objectness score and the coordinates of the rectangle.\n",
        "\n",
        "Stage 2 : \n",
        "\n",
        "\n",
        "\\\n",
        "Now the backbone network is a simple vanilla pre-trained Resnet network. So we will discuss the next part, i.e. the Stage 1 Region proposal network."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRlfpnLtzJ0R"
      },
      "source": [
        "##1.2 Region Proposal Network & Anchor Boxes\n",
        "The Region proposal network produces regions of interest from the feature map that it recieves as input. It does this by moving a sliding window of size `n*n` along the feature map. Each window thus obtained is then fed to the fully connnected layers - box regression layers and box-classification layer. In addition, it is also fed to the network that predicts the masks for the object.\n",
        "\n",
        "\\\n",
        "At each sliding-window location, we simultaneously\n",
        "predict multiple region proposals, where the number\n",
        "of maximum possible proposals for each location is\n",
        "denoted as k. So the regression layer has 4k outputs encoding\n",
        "the coordinates of k boxes, and the classification layer outputs\n",
        "2k scores that estimate probability of object or not\n",
        "object for each proposal. The k proposals are parameterized relative to k reference boxes, which we call `anchors`. An anchor is centered at the sliding window\n",
        "in question, and is associated with a scale and aspect\n",
        "ratio (Second figure below). By default we use 3 scales and\n",
        "3 aspect ratios, yielding k = 9 anchors at each sliding\n",
        "position. For a convolutional feature map of a size\n",
        "W × H (typically ∼2,400), there are W Hk anchors in\n",
        "total.\n",
        "\n",
        "Below is an illustration of anchor boxes distributed over the input image(In practise the anchor boxes are decided over the feature map from the backbone network. Also the number of anchor boxes will be considerably more than shown here.)\n",
        "\n",
        "<img src=\"https://miro.medium.com/max/2160/1*ryi4m758IblLvDLhl_l9aA.png\" alt=\"MarineGEO circle logo\" style=\"height: 100px; width:100px;\"/>\n",
        "\n",
        "\\\n",
        "Below is an illustration of the different scales and aspect ratios of the anchor boxes that are used in the architecture.\n",
        "<img src=\"https://miro.medium.com/max/1400/0*n6pZEyvW47nlcdQz.\" alt=\"MarineGEO circle logo\" style=\"height: 100px; width:100px;\"/>\n",
        "\n",
        "\n",
        "\\\n",
        "Now the output of the Region proposal network are `anchor class` and the refined `coordinates` for the bounding boxes.\n",
        "\n",
        "\n",
        "*   The `anchor class` is either `background` or `foreground`.\n",
        "*   The bounding boxes that are predicted often don't center over the object perfectly. Hence a delta for the coordinates is estimated by the RPN network which are the refined `coordinates`.\n",
        "\\\n",
        "After this, the predictions from the RPN are filtered based on the anchor class. Also the bounding boxes that are closely located to each other are eliminated by measuring their overlap by a technique called Non-maxima suppression. Thus, a final set of proposals are selected for the next stage.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vpQGcCK4zFIv"
      },
      "source": [
        "##ROI Pool vs ROI Align\n",
        "Region of Interest Pooling operation is a simple neural net layer that performs maxpooling on inputs of non-uniform sizes to gain a fixed size feature map"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QVXFHMZ1YSFJ"
      },
      "source": [
        "##Mask Representations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TarfYbMQzKKL"
      },
      "source": [
        "## Loss Function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TmJdVKs-zKiD"
      },
      "source": [
        "##Training the network"
      ]
    }
  ]
}